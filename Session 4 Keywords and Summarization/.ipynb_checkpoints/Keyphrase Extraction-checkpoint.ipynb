{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the simplest yet most powerful techniques of extracting important information from unstructured text documents. Keyphrase extraction, also known as terminology extraction, is the process of extracting key terms or phrases from a body of unstructured text so that the core themes are captured. This technique falls under the broad umbrella of information retrieval and extraction. Keyphrase extraction is useful in many areas, some of which are mentioned here:\n",
    "\n",
    "- Semantic web\n",
    "- Query based search engines and crawlers\n",
    "- Recommendation systems\n",
    "- Tagging systems\n",
    "- Document similarity\n",
    "- Translation\n",
    "\n",
    "Keyphrase extraction is often the starting point for carrying out more complex tasks in text analytics or natural language processing and the output can act as features for more complex systems. There are various approaches for keyphrase extraction; we cover the following two major techniques:\n",
    "\n",
    "- Collocations\n",
    "- Weighted tag-based phrase extraction\n",
    "\n",
    "An important point to remember is that we will be extracting phrases, which are usually a collection of words and can sometimes just be single words. If you are extracting keywords, that is also known as keyword extraction and it is a subset of keyphrase extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keyword --> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations\n",
    "\n",
    "The term collocation is borrowed from analyzing corpora and linguistics. A collocation can be defined as a sequence or group of words that tend to occur frequently and this frequency tends to be more than what could be termed a random or chance occurrence. Various types of collocations can be formed based on parts of speech like nouns, verbs, and so on. There are various ways to extract collocations and one of the best ways to do it is to use an n-gram grouping or segmentation approach. This is where we construct n-grams out of a corpus and then count the frequency of each n-gram and rank them based on their frequency of occurrence to get the most frequent n-gram collocations.\n",
    "\n",
    "The idea is to have a corpus of documents (paragraphs or sentences), tokenize them to form sentences, flatten the list of sentences to form one large sentence or string over which we slide a window of size n based on the n-gram range, and compute n-grams across the string. Once they are computed, we count each n-gram based on its frequency of occurrence and then rank it. This yields the most frequent collocations on the basis\n",
    "of frequency. We implement this from scratch initially so that you can understand the algorithm better and then we use some of NLTK’s built-in capabilities to depict it.\n",
    "\n",
    "Let’ start by loading some necessary dependencies and a corpus on which we will be computing collocations. We use the NLTK Gutenberg corpus’s book, Lewis Carroll’s Alice in Wonderland, as our corpus. We also normalize the corpus to standardize the text content using our handy text_normalizer module, which we built and used in the previous chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/olmos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/olmos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/olmos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg \n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "import re\n",
    "\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopwords_en = stopwords.words('english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Modules\n",
    "lemmatizer  = WordNetLemmatizer()\n",
    "snowball = SnowballStemmer('english')\n",
    "stopwords   = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation = string.punctuation\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = []\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        token = re.sub(r'[^a-zA-Z\\s]', '', token, re.I|re.A)\n",
    "        token = token.lower() \n",
    "        #token = lemmatizer.lemmatize(token)\n",
    "        #token = snowball.stem(token)\n",
    "        if token not in stopwords and token not in punctuation and token.isalnum():\n",
    "            normalized_text.append(token)\n",
    "            \n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "alice = gutenberg.raw(fileids='carroll-alice.txt') \n",
    "\n",
    "alice_norm = normalize(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ngrams(sequence, n):\n",
    "    return list(\n",
    "            zip(*(sequence[index:] for index in range(n)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (3, 4)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ngrams([1,2,3,4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (2, 3, 4)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ngrams([1,2,3,4], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted list: [(4, 1), (2, 2), (1, 3), (3, 4)]\n"
     ]
    }
   ],
   "source": [
    "# take the second element for sort\n",
    "def take_second(elem):\n",
    "    return elem[1]\n",
    "\n",
    "\n",
    "# random list\n",
    "random = [(2, 2), (3, 4), (4, 1), (1, 3)]\n",
    "\n",
    "# sort list with key\n",
    "sorted_list = sorted(random, key=take_second)\n",
    "sorted_list = sorted(random, key=itemgetter(1))\n",
    "\n",
    "# print list\n",
    "print('Sorted list:', sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngrams(flat_corpus, ngram_val=1, limit=5):\n",
    "    \n",
    "    ngrams = compute_ngrams(flat_corpus, ngram_val) \n",
    "    ngrams_freq_dist = nltk.FreqDist(ngrams) \n",
    "    sorted_ngrams_fd = sorted(ngrams_freq_dist.items(),key=itemgetter(1), reverse=True) \n",
    "    sorted_ngrams = sorted_ngrams_fd[0:limit]\n",
    "    sorted_ngrams = [(' '.join(text), freq) for text, freq in sorted_ngrams]\n",
    "    \n",
    "    return sorted_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said alice', 123),\n",
       " ('mock turtle', 55),\n",
       " ('march hare', 31),\n",
       " ('said king', 29),\n",
       " ('thought alice', 26),\n",
       " ('ca nt', 25),\n",
       " ('wo nt', 23),\n",
       " ('white rabbit', 22),\n",
       " ('said hatter', 22),\n",
       " ('said mock', 20)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_ngrams(alice_norm, ngram_val=2,limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said mock turtle', 20),\n",
       " ('said march hare', 9),\n",
       " ('nt wo nt', 7),\n",
       " ('poor little thing', 6),\n",
       " ('wo nt wo', 6),\n",
       " ('little golden key', 5),\n",
       " ('certainly said alice', 5),\n",
       " ('white kid gloves', 5),\n",
       " ('said alice nt', 5),\n",
       " ('march hare said', 5)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_ngrams(alice_norm, ngram_val=3,limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his output shows us sequences of two and three words generated by n-grams along with the number of times they occur throughout the corpus. We can see that most of the collocations point to people who are speaking something as “said <person>”. We also see the people who are popular characters in Alice in Wonderland, like the mock turtle, the king, the rabbit, the hatter, and Alice are depicted in the collocations.\n",
    "    \n",
    "We now look at NLTK’s collocation finders, which enable us to find collocations using various measures like raw frequencies, pointwise mutual information, and so on. Just to explain briefly, pointwise mutual information can be computed for two events or terms as the logarithm of the ratio of the probability of them occurring together by the product of their individual probabilities, assuming that they are independent of each other. Mathematically, we can represent it as follows:\n",
    "    \n",
    "    \n",
    "$$pmi(x,y) = \\log \\frac{p(x,y)}{p(x)p(y)}$$\n",
    "    \n",
    "This measure is symmetric. The following code snippet shows us how to compute these collocations using these measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder \n",
    "from nltk.collocations import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(alice_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.collocations.BigramCollocationFinder at 0x7fd289b907f0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'alice'),\n",
       " ('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'king'),\n",
       " ('thought', 'alice'),\n",
       " ('ca', 'nt'),\n",
       " ('wo', 'nt'),\n",
       " ('said', 'hatter'),\n",
       " ('white', 'rabbit'),\n",
       " ('said', 'mock')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(BigramAssocMeasures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'alice'),\n",
       " ('white', 'rabbit'),\n",
       " ('ca', 'nt'),\n",
       " ('wo', 'nt'),\n",
       " ('join', 'dance'),\n",
       " ('soo', 'oop'),\n",
       " ('minute', 'two'),\n",
       " ('said', 'king')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(BigramAssocMeasures.likelihood_ratio, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abide', 'figures'),\n",
       " ('acceptance', 'elegant'),\n",
       " ('accounting', 'tastes'),\n",
       " ('accustomed', 'usurpation'),\n",
       " ('act', 'crawling'),\n",
       " ('adding', 'youre'),\n",
       " ('adjourn', 'immediate'),\n",
       " ('adoption', 'energetic'),\n",
       " ('affair', 'trusts'),\n",
       " ('agony', 'terror')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(BigramAssocMeasures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('said', 'march', 'hare'),\n",
       " ('nt', 'wo', 'nt'),\n",
       " ('poor', 'little', 'thing'),\n",
       " ('wo', 'nt', 'wo'),\n",
       " ('certainly', 'said', 'alice'),\n",
       " ('little', 'golden', 'key'),\n",
       " ('march', 'hare', 'said'),\n",
       " ('mock', 'turtle', 'said'),\n",
       " ('said', 'alice', 'nt')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import TrigramCollocationFinder \n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "\n",
    "trifinder = TrigramCollocationFinder.from_words(alice_norm)\n",
    "\n",
    "trifinder.nbest(TrigramAssocMeasures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('bed', 'various', 'pretexts'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherrytart', 'custard', 'pineapple'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trifinder.nbest(TrigramAssocMeasures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('mock', 'turtle', 'sighed'),\n",
       " ('mock', 'turtle', 'replied'),\n",
       " ('mock', 'turtle', 'soup'),\n",
       " ('different', 'mock', 'turtle'),\n",
       " ('ix', 'mock', 'turtle'),\n",
       " ('mock', 'turtle', 'capering'),\n",
       " ('mock', 'turtle', 'seals'),\n",
       " ('cried', 'mock', 'turtle'),\n",
       " ('miserable', 'mock', 'turtle'),\n",
       " ('mock', 'turtle', 'drive'),\n",
       " ('mock', 'turtle', 'persisted'),\n",
       " ('mock', 'turtle', 'recovered'),\n",
       " ('mock', 'turtle', 'sang'),\n",
       " ('mock', 'turtle', 'yawned'),\n",
       " ('mock', 'turtle', 'youve'),\n",
       " ('mystery', 'mock', 'turtle'),\n",
       " ('mock', 'turtle', 'went'),\n",
       " ('obliged', 'mock', 'turtle'),\n",
       " ('show', 'mock', 'turtle')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trifinder.nbest(TrigramAssocMeasures.likelihood_ratio, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAG OF N-GRAMS!!\n",
    "\n",
    "https://radimrehurek.com/gensim/models/phrases.html\n",
    "\n",
    "http://uc-r.github.io/creating-text-features\n",
    "\n",
    "\n",
    "https://svn.spraakdata.gu.se/repos/gerlof/pub/www/Docs/npmi-pfd.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT = \"\"\"\n",
    "The Elder Scrolls V: Skyrim is an action role-playing video game developed by Bethesda Game Studios \n",
    "and published by Bethesda Softworks. It is the fifth main installment in The Elder Scrolls series, \n",
    "following The Elder Scrolls IV: Oblivion.\n",
    "The game's main story revolves around the player character's quest to defeat Alduin the World-Eater, \n",
    "a dragon who is prophesied to destroy the world. The game is set 200 years after the events of Oblivion \n",
    "and takes place in the fictional province of Skyrim. Over the course of the game, the player completes \n",
    "quests and develops the character by improving skills. The game continues the open-world tradition of \n",
    "its predecessors by allowing the player to travel anywhere in the game world at any time, and to ignore \n",
    "or postpone the main storyline indefinitely.\n",
    "The team opted for a unique and more diverse open world than Oblivion's Imperial Province of Cyrodiil, \n",
    "which game director and executive producer Todd Howard considered less interesting by comparison. \n",
    "The game was released to critical acclaim, with reviewers particularly mentioning the character advancement \n",
    "and setting, and is considered to be one of the greatest video games of all time.\n",
    "\n",
    "\n",
    "The Elder Scrolls V: Skyrim is an action role-playing game, playable from either a first or \n",
    "third-person perspective. The player may freely roam over the land of Skyrim which is an open world \n",
    "environment consisting of wilderness expanses, dungeons, cities, towns, fortresses, and villages. \n",
    "Players may navigate the game world more quickly by riding horses or by utilizing a fast-travel system \n",
    "which allows them to warp to previously discovered locations. The game's main quest can be completed or \n",
    "ignored at the player's preference after the first stage of the quest is finished. However, some quests \n",
    "rely on the main storyline being at least partially completed. Non-player characters (NPCs) populate the \n",
    "world and can be interacted with in a number of ways: the player may engage them in conversation, \n",
    "marry an eligible NPC, kill them or engage in a nonlethal \"brawl\". The player may \n",
    "choose to join factions which are organized groups of NPCs — for example, the Dark Brotherhood, a band \n",
    "of assassins. Each of the factions has an associated quest path to progress through. Each city and town \n",
    "in the game world has jobs that the player can engage in, such as farming.\n",
    "\n",
    "Players have the option to develop their character. At the beginning of the game, players create \n",
    "their character by selecting their sex and choosing between one of several races including humans, \n",
    "orcs, elves, and anthropomorphic cat or lizard-like creatures and then customizing their character's \n",
    "appearance. Over the course of the game, players improve their character's skills which are numerical \n",
    "representations of their ability in certain areas. There are eighteen skills divided evenly among the \n",
    "three schools of combat, magic, and stealth. When players have trained skills enough to meet the \n",
    "required experience, their character levels up. Health is depleted primarily when the player \n",
    "takes damage and the loss of all health results in death. Magicka is depleted by the use of spells, \n",
    "certain poisons and by being struck by lightning-based attacks. Stamina determines the player's \n",
    "effectiveness in combat and is depleted by sprinting, performing heavy \"power attacks\" \n",
    "and being struck by frost-based attacks. Skyrim is the first entry in The Elder Scrolls to \n",
    "include dragons in the game's wilderness. Like other creatures, dragons are generated randomly in \n",
    "the world and will engage in combat with NPCs, creatures and the player. Some dragons may attack \n",
    "cities and towns when in their proximity. The player character can absorb the souls of dragons \n",
    "in order to use powerful spells called \"dragon shouts\" or \"Thu'um\". A regeneration \n",
    "period limits the player's use of shouts in gameplay.\n",
    "\n",
    "Skyrim is set around 200 years after the events of The Elder Scrolls IV: Oblivion, although it is \n",
    "not a direct sequel. The game takes place in Skyrim, a province of the Empire on the continent of \n",
    "Tamriel, amid a civil war between two factions: the Stormcloaks, led by Ulfric Stormcloak, and the \n",
    "Imperial Legion, led by General Tullius. The player character is a Dragonborn, a mortal born with \n",
    "the soul and power of a dragon. Alduin, a large black dragon who returns to the land after being \n",
    "lost in time, serves as the game's primary antagonist. Alduin is the first dragon created by Akatosh, \n",
    "one of the series' gods, and is prophesied to destroy and consume the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis\n",
    "\n",
    "http://www.kiv.zcu.cz/~jstein/publikace/isim2004.pdf\n",
    "\n",
    "https://github.com/dipanjanS/text-analytics-with-python/blob/master/New-Second-Edition/Ch06%20-%20Text%20Summarization%20and%20Topic%20Models/Ch06e%20-%20Document%20Summarization.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of tokens: the input is the preprocessed corpus \n",
    "\n",
    "sentences = nltk.sent_tokenize(DOCUMENT)\n",
    "\n",
    "norm_text = [normalize(s) for s in sentences]\n",
    "\n",
    "D = gensim.corpora.Dictionary(norm_text)\n",
    "\n",
    "corpus_bow = [D.doc2bow(doc) for doc in norm_text]\n",
    "\n",
    "model = TfidfModel(corpus_bow)  \n",
    "\n",
    "corpus_tfidf = model[corpus_bow]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import corpus2dense, corpus2csc\n",
    "\n",
    "n_tokens = len(D)\n",
    "num_docs = len(corpus_bow)\n",
    "# Convert BoW representacion\n",
    "corpus_bow_dense = corpus2dense(corpus_bow, num_terms=n_tokens, num_docs=num_docs).T\n",
    "corpus_bow_sparse = corpus2csc(corpus_bow, num_terms=n_tokens, num_docs=num_docs).T\n",
    "# Convert TFIDF representacion\n",
    "corpus_tfidf_dense = corpus2dense(corpus_tfidf, num_terms=n_tokens, num_docs=num_docs).T\n",
    "corpus_tfidf_sparse = corpus2csc(corpus_tfidf, num_terms=n_tokens, num_docs=num_docs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 270)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf_dense.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Rank & Page Rank\n",
    "\n",
    "\n",
    "\n",
    "https://radimrehurek.com/gensim_3.8.3//auto_examples/tutorials/run_summarization.html#sphx-glr-auto-examples-tutorials-run-summarization-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rake algorithm\n",
    "\n",
    "Rapid Automatic Keyword Extraction (RAKE) is a well-known keyword extraction method which uses a list of stopwords and phrase delimiters to detect the most relevant words or phrases in a piece of text.\n",
    "\n",
    "Then, the algorithm splits the text at phrase delimiters and stopwords to create candidate expressions. \n",
    "\n",
    "Once the text has been split, the algorithm creates a matrix of word co-occurrences. Each row shows the number of times that a given content word co-occurs with every other content word in the candidate phrases\n",
    "\n",
    "After that matrix is built, words are given a score. That score can be calculated as the degree of a word in the matrix (i.e. the sum of the number of co-occurrences the word has with any other content word in the text), as the word frequency (i.e. the number of times the word appears in the text), or as the degree of the word divided by its frequency.\n",
    "\n",
    "As from above, we know that RAKE classifies the main content bearing word as Candidate Keyword by parsing the document with the help of stop words and phrase delimiters. This is done basically by some of the following steps, firstly the document text is split into an array of words by the specific word delimiters, and secondly, the array is again split into a sequence of contiguous words at phrase delimiters and stop word positions. Finally, the words that lie in the same sequence are assigned the same position in the text and together are considered as a candidate key.\n",
    "\n",
    "After identifying all the candidate keywords from the text data, a graph of word co-occurrence is generated which calculates the score for each candidate keyword and defined as the member word score. With the help of this graph, we evaluate several metrics for calculating word scores, based on the degree and frequency of the vertices in the graph.\n",
    "\n",
    "As we know that Rake splits candidate keywords by stop words, so the extracted keywords do not contain interior stop words, therefore an interest wan expressed in identifying keywords that contain interior stop words as the axis of evil. To find keywords that adjoin one another at least twice in the same document and the same order. For this purpose, a new candidate keyword is created as a combination of those keywords and the interior stop words. In this part, we should understand that very few linked words are only extracted which add significance.\n",
    "\n",
    "https://medium.datadriveninvestor.com/rake-rapid-automatic-keyword-extraction-algorithm-f4ec17b2886c\n",
    "\n",
    "\n",
    "https://catalogimages.wiley.com/images/db/pdf/9780470749821.excerpt.pdf\n",
    "\n",
    "Figura RAKE vs TextRank\n",
    "\n",
    "https://monkeylearn.com/keyword-extraction/\n",
    "\n",
    "https://pypi.org/project/rake-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rake-nltk in /Users/olmos/opt/anaconda3/envs/work/lib/python3.6/site-packages (1.0.4)\r\n",
      "Requirement already satisfied: nltk in /Users/olmos/opt/anaconda3/envs/work/lib/python3.6/site-packages (from rake-nltk) (3.5)\r\n",
      "Requirement already satisfied: tqdm in /Users/olmos/opt/anaconda3/envs/work/lib/python3.6/site-packages (from nltk->rake-nltk) (4.47.0)\r\n",
      "Requirement already satisfied: joblib in /Users/olmos/opt/anaconda3/envs/work/lib/python3.6/site-packages (from nltk->rake-nltk) (0.16.0)\r\n",
      "Requirement already satisfied: click in /Users/olmos/opt/anaconda3/envs/work/lib/python3.6/site-packages (from nltk->rake-nltk) (7.1.2)\r\n",
      "Requirement already satisfied: regex in /Users/olmos/opt/anaconda3/envs/work/lib/python3.6/site-packages (from nltk->rake-nltk) (2020.6.8)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['executive producer todd howard considered less interesting',\n",
       " 'eighteen skills divided evenly among',\n",
       " 'several races including humans',\n",
       " 'main story revolves around',\n",
       " 'set around 200 years',\n",
       " 'player may freely roam',\n",
       " 'open world environment consisting',\n",
       " 'use powerful spells called',\n",
       " 'playing video game developed',\n",
       " 'dragons may attack cities',\n",
       " 'set 200 years',\n",
       " 'greatest video games',\n",
       " 'player may choose',\n",
       " 'reviewers particularly mentioning',\n",
       " 'regeneration period limits',\n",
       " 'previously discovered locations',\n",
       " 'fifth main installment',\n",
       " 'trained skills enough',\n",
       " 'elder scrolls v',\n",
       " 'elder scrolls iv',\n",
       " 'players may navigate',\n",
       " 'main storyline indefinitely',\n",
       " 'player takes damage',\n",
       " 'large black dragon',\n",
       " 'player completes quests',\n",
       " 'diverse open world',\n",
       " 'player may engage',\n",
       " 'least partially completed',\n",
       " 'associated quest path',\n",
       " 'bethesda game studios',\n",
       " 'game takes place',\n",
       " 'elder scrolls series',\n",
       " 'first dragon created',\n",
       " 'elder scrolls',\n",
       " 'playing game',\n",
       " 'main storyline',\n",
       " 'takes place',\n",
       " 'main quest',\n",
       " 'game world',\n",
       " 'improving skills',\n",
       " 'player characters',\n",
       " 'quests rely',\n",
       " 'bethesda softworks',\n",
       " 'world tradition',\n",
       " 'player character',\n",
       " 'game director',\n",
       " 'game continues',\n",
       " 'include dragons',\n",
       " 'um \".',\n",
       " 'ulfric stormcloak',\n",
       " 'travel system',\n",
       " 'travel anywhere',\n",
       " 'three schools',\n",
       " 'team opted',\n",
       " 'stamina determines',\n",
       " 'riding horses',\n",
       " 'required experience',\n",
       " 'primary antagonist',\n",
       " 'players improve',\n",
       " 'players create',\n",
       " 'person perspective',\n",
       " 'performing heavy',\n",
       " 'organized groups',\n",
       " 'numerical representations',\n",
       " 'mortal born',\n",
       " 'imperial legion',\n",
       " 'generated randomly',\n",
       " 'general tullius',\n",
       " 'first stage',\n",
       " 'first entry',\n",
       " 'eligible npc',\n",
       " 'direct sequel',\n",
       " 'dark brotherhood',\n",
       " 'critical acclaim',\n",
       " 'considered',\n",
       " 'civil war',\n",
       " 'certain poisons',\n",
       " 'certain areas',\n",
       " 'brawl \".',\n",
       " 'based attacks',\n",
       " 'anthropomorphic cat',\n",
       " 'action role',\n",
       " 'dragon shouts',\n",
       " 'character levels',\n",
       " 'character advancement',\n",
       " 'two factions',\n",
       " 'join factions',\n",
       " 'imperial province',\n",
       " 'fictional province',\n",
       " 'wilderness expanses',\n",
       " 'power attacks',\n",
       " 'npcs —',\n",
       " 'health results',\n",
       " 'depleted primarily',\n",
       " 'defeat alduin',\n",
       " 'like creatures',\n",
       " 'skills',\n",
       " 'open',\n",
       " 'player',\n",
       " 'use',\n",
       " 'spells',\n",
       " 'cities',\n",
       " 'world',\n",
       " 'game',\n",
       " 'dragons',\n",
       " 'dragon',\n",
       " 'series',\n",
       " 'quest',\n",
       " 'players',\n",
       " 'first',\n",
       " 'engage',\n",
       " 'completed',\n",
       " 'character',\n",
       " 'province',\n",
       " 'factions',\n",
       " 'wilderness',\n",
       " 'shouts',\n",
       " 'power',\n",
       " 'npcs',\n",
       " 'like',\n",
       " 'health',\n",
       " 'depleted',\n",
       " 'creatures',\n",
       " 'alduin',\n",
       " 'ways',\n",
       " 'warp',\n",
       " 'villages',\n",
       " 'utilizing',\n",
       " 'unique',\n",
       " 'towns',\n",
       " 'town',\n",
       " 'time',\n",
       " 'thu',\n",
       " 'third',\n",
       " 'tamriel',\n",
       " 'struck',\n",
       " 'stormcloaks',\n",
       " 'stealth',\n",
       " 'sprinting',\n",
       " 'souls',\n",
       " 'soul',\n",
       " 'skyrim',\n",
       " 'sex',\n",
       " 'setting',\n",
       " 'serves',\n",
       " 'selecting',\n",
       " 'returns',\n",
       " 'released',\n",
       " 'quickly',\n",
       " 'published',\n",
       " 'proximity',\n",
       " 'prophesied',\n",
       " 'progress',\n",
       " 'preference',\n",
       " 'predecessors',\n",
       " 'postpone',\n",
       " 'populate',\n",
       " 'playable',\n",
       " 'order',\n",
       " 'orcs',\n",
       " 'option',\n",
       " 'one',\n",
       " 'oblivion',\n",
       " 'number',\n",
       " 'nonlethal',\n",
       " 'non',\n",
       " 'meet',\n",
       " 'marry',\n",
       " 'magicka',\n",
       " 'magic',\n",
       " 'lost',\n",
       " 'loss',\n",
       " 'lizard',\n",
       " 'lightning',\n",
       " 'led',\n",
       " 'land',\n",
       " 'kill',\n",
       " 'jobs',\n",
       " 'interacted',\n",
       " 'ignored',\n",
       " 'ignore',\n",
       " 'however',\n",
       " 'gods',\n",
       " 'gameplay',\n",
       " 'frost',\n",
       " 'fortresses',\n",
       " 'following',\n",
       " 'finished',\n",
       " 'fast',\n",
       " 'farming',\n",
       " 'example',\n",
       " 'events',\n",
       " 'empire',\n",
       " 'elves',\n",
       " 'either',\n",
       " 'effectiveness',\n",
       " 'eater',\n",
       " 'dungeons',\n",
       " 'dragonborn',\n",
       " 'develops',\n",
       " 'develop',\n",
       " 'destroy',\n",
       " 'death',\n",
       " 'cyrodiil',\n",
       " 'customizing',\n",
       " 'course',\n",
       " 'conversation',\n",
       " 'continent',\n",
       " 'consume',\n",
       " 'comparison',\n",
       " 'combat',\n",
       " 'city',\n",
       " 'choosing',\n",
       " 'beginning',\n",
       " 'band',\n",
       " 'assassins',\n",
       " 'appearance',\n",
       " 'amid',\n",
       " 'although',\n",
       " 'allows',\n",
       " 'allowing',\n",
       " 'akatosh',\n",
       " 'absorb',\n",
       " 'ability']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "r = Rake() # Uses stopwords for english from NLTK, and all puntuation characters.\n",
    "\n",
    "r.extract_keywords_from_text(DOCUMENT)\n",
    "\n",
    "r.get_ranked_phrases() # To get keyword phrases ranked highest to lowest.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
